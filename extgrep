#!/usr/bin/env python3.7
#
# Copyright (C) 2019 The University of Sheffield, UK
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.
#
# SPDX-License-Identifier: GPL-3.0-or-later

import datetime
import argparse
import io
import fnmatch
import os
import logging
import re
import json
import sys
import operator
import tarfile
import zlib
from functools import partial, reduce
from colorama import init, Fore
from multiprocessing import Pool
from zipfile import ZipFile

import dateutil
import dateutil.parser
import jsbeautifier
import importlib.util

from zipfile import ZipFile

from ExtensionCrawler.config import (const_log_format, const_basedir)
from ExtensionCrawler.archive import iter_tar_entries
from ExtensionCrawler.config import get_local_archive_dir
from ExtensionCrawler.js_decomposer import init_file_info
from ExtensionCrawler.js_mincer import mince_js


def is_source_file(zipentry):
    """Test if filename indicates file with C-style comment."""
    return (zipentry.filename.endswith(".js") or zipentry.filename.endswith(".js.gz")
            or zipentry.filename.endswith(".jgz") or zipentry.filename.endswith(".jsg")
            or zipentry.filename.endswith(".css.gz") or zipentry.filename.endswith(".c")
            or zipentry.filename.endswith(".cpp") or zipentry.filename.endswith(".java"))

def import_regexs(path):
    spec = importlib.util.spec_from_file_location("MinerStrings", path)
    module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(module)
    return module

def get_etag(header_tarentry):
    headers_content = header_tarentry.read().decode().replace(
            '"', '\\"').replace("'", '"')
    headers_json = json.loads(headers_content)
    if "ETag" in headers_json:
        return headers_json["ETag"]

def get_name_and_version(overview_tarentry):
    contents = overview_tarentry.read().decode()

    # Extract extension name
    match = re.search("""<meta itemprop="name" content="(.*?)"\s*/>""",
                      contents)
    name = match.group(1) if match else None

    # Extract extension version
    match = re.search(
        """<meta itemprop="version" content="(.*?)"\s*/>""", contents)
    version = match.group(1) if match else None

    return name, version

def handle_extid(conf, extid):
    miner_strings = import_regexs(conf.REGEXP_FILE).MinerStrings()

    results = {}

    still_in_store = None
    crx_etags = [None]
    for tarentry, tarfile in iter_tar_entries(conf.archive_dir, extid):
        if tarentry.isdir():
            continue
        date = tarentry.name.split("/")[1]
        if conf.from_date and not (conf.from_date <= date):
            continue
        if conf.latest_date and not (date <= conf.latest_date):
            continue

        if date not in results:
            results[date] = {}
            results[date]["crx_etag"] = None
            results[date]["name"] = None
            results[date]["version"] = None
            results[date]["matches"] = []

        tar_file_name = tarentry.name.split("/")[-1]

        if tar_file_name.endswith(".crx.headers"):
            crx_etag = get_etag(tarfile)
            results[date]["crx_etag"] = crx_etag
            if crx_etag:
                crx_etags += [crx_etag]

        if tar_file_name == "overview.html":
            results[date]["name"], results[date]["version"] = get_name_and_version(tarfile)

        if tar_file_name == "overview.html.status":
            still_in_store = tarfile.read().decode().startswith("2")

        if tar_file_name.endswith(".crx"):
            with ZipFile(tarfile) as zf:
                for zipentry in zf.infolist():
                    if is_source_file(zipentry):
                        with zf.open(zipentry) as f:
                            for block in mince_js(io.TextIOWrapper(f, encoding="utf-8", errors="surrogateescape")):

                                file_lines = []
                                file_lines += block.content.splitlines()
                                file_lines += "".join(map(lambda x: x[1], block.string_literals)).splitlines()

                                for search_tag in miner_strings.strings.keys():
                                    for search_string in miner_strings.strings[search_tag]:
                                        for line in file_lines:
                                            if search_string in line:
                                                results[date]["matches"] += [[zipentry.filename, search_tag, search_string]]
                                                break

                                for search_tag in miner_strings.patterns.keys():
                                    for search_pattern in miner_strings.patterns[search_tag]:
                                        for line in file_lines:
                                            m = re.search(search_pattern, line)
                                            if m:
                                                results[date]["matches"] += [[zipentry.filename, search_tag, m.group()]]
                                                break
                                #for extid, still_in_store, most_recent_crx_etag, date, crx_etag, name, version, path, tag, match

    for date in sorted(results.keys()):
        result = results[date]
        for match in result["matches"]:
            print("|".join([str(x) for x in ([extid, still_in_store, crx_etags[-1], date, result["crx_etag"], result["name"], result["version"]] + match)]))


def main(conf):
    logger = logging.getLogger()
    ch = logging.StreamHandler(sys.stderr)
    ch.setFormatter(logging.Formatter(const_log_format()))
    logger.addHandler(ch)
    if conf.verbose:
        logger.setLevel(logging.DEBUG)
    else:
        logger.setLevel(logging.WARNING)

    with open(conf.EXTID_FILE) as f:
        print("|".join(["extid", "still_in_store", "most_recent_crx_etag", "date", "crx_etag", "name", "version", "path", "tag", "match"]))
        for extid in [l.strip() for l in f.readlines()]:
            handle_extid(conf, extid)



if __name__ == "__main__":
    main_parser = argparse.ArgumentParser(
        formatter_class=argparse.RawTextHelpFormatter,
        description='Grep for extensions.')
    main_parser.add_argument(
        'REGEXP_FILE',
        help='python file with regular expressions')
    main_parser.add_argument(
        'EXTID_FILE',
        help='file with extension ids')
    main_parser.add_argument(
        '-v',
        '--verbose',
        action='store_true',
        default=False,
        help='increase verbosity')


    main_parser.add_argument(
        '-D',
        '--latest-date',
        metavar='DATE',
        type=str,
        help='select latest crx from tar, released before DATE.\n' +
        'Together with --from-date, specifies all crx released in specified\n'
        + 'date range.')

    main_parser.add_argument(
        '-d',
        '--from-date',
        metavar='DATE',
        type=str,
        help='select oldest crx from tar released after DATE.\n' +
        'Together with --latest-date, specifies all crx released in specified\n'
        + 'date range.')

    main_parser.add_argument(
        '-a',
        '--archive-dir',
        metavar='archive',
        type=str,
        default=const_basedir(),
        help='archive directory')

    # comment_group = main_parser.add_argument_group('comment blocks')
    # comment_group.add_argument(
    #     '-g',
    #     '--group-single-line-comments',
    #     help='Group consecutive singe-line comments into blocks')
    # comment_group.add_argument(
    #     '-c',
    #     '--reg-exp-comments',
    #     metavar='REGEXP',
    #     type=str,
    #     nargs='+',
    #     help='search comments for regular expression')

    # source_group = main_parser.add_argument_group('source blocks')
    # source_group.add_argument(
    #     '-b',
    #     '--beautify',
    #     action='store_true',
    #     default=False,
    #     help='beautify source code')
    # source_group.add_argument(
    #     '-s',
    #     '--reg-exp-source',
    #     metavar='REGEXP',
    #     type=str,
    #     nargs='+',
    #     help='search source for regular expression')

    # strings_group = main_parser.add_argument_group('string literals')
    # strings_group.add_argument(
    #     '-j',
    #     '--join-string-literals',
    #     action='store_true',
    #     help='join string literals (heuristic)')
    # strings_group.add_argument(
    #     '-l',
    #     '--reg-exp-string-literals',
    #     metavar='REGEXP',
    #     type=str,
    #     nargs='+',
    #     help='search string literals for regular expression')
    main_conf = main_parser.parse_args()

    sys.exit(main(main_conf))
