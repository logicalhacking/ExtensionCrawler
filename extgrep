#!/usr/bin/env python3.7
#
# Copyright (C) 2019 The University of Sheffield, UK
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.
#
# SPDX-License-Identifier: GPL-3.0-or-later

import argparse
import io
import logging
import re
import json
import sys
import importlib.util

from zipfile import ZipFile

from ExtensionCrawler.config import (const_log_format, const_basedir)
from ExtensionCrawler.archive import iter_tar_entries, iter_tar_entries_by_date
from ExtensionCrawler.js_mincer import mince_js


def is_source_file(zipentry):
    """Test if filename indicates file with C-style comment."""
    return (zipentry.filename.endswith(".js") or zipentry.filename.endswith(".js.gz")
            or zipentry.filename.endswith(".jgz") or zipentry.filename.endswith(".jsg")
            or zipentry.filename.endswith(".css.gz") or zipentry.filename.endswith(".c")
            or zipentry.filename.endswith(".cpp") or zipentry.filename.endswith(".java"))

def import_regexs(path):
    spec = importlib.util.spec_from_file_location("MinerStrings", path)
    module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(module)
    return module

def get_etag(headers_content):
    headers_content = headers_content.replace(
            '"', '\\"').replace("'", '"')
    headers_json = json.loads(headers_content)
    if "ETag" in headers_json:
        return headers_json["ETag"]

def get_name_and_version(overview_contents):
    # Extract extension name
    match = re.search("""<meta itemprop="name" content="(.*?)"\s*/>""",
                      overview_contents)
    name = match.group(1) if match else None

    # Extract extension version
    match = re.search(
        """<meta itemprop="version" content="(.*?)"\s*/>""", overview_contents)
    version = match.group(1) if match else None

    return name, version

def handle_extid(conf, extid):
    miner_strings = import_regexs(conf.REGEXP_FILE).MinerStrings()

    results = []

    still_in_store = None
    crx_etags = [None]
    for date, tups in iter_tar_entries_by_date(conf.archive_dir, extid):
        if conf.from_date and not (conf.from_date <= date):
            continue
        if conf.latest_date and not (date <= conf.latest_date):
            continue

        crx_etag = None
        name = None
        version = None
        matches = []
        for tarentry, tarfile in tups:
            tarentry_filename = tarentry.name.split("/")[-1]

            if tarentry_filename.endswith(".crx.headers"):
                crx_etag = get_etag(tarfile.read().decode())
                if crx_etag:
                    crx_etags += [crx_etag]

            if tarentry_filename == "overview.html":
                name, version = get_name_and_version(tarfile.read().decode())

            if tarentry_filename == "overview.html.status":
                still_in_store = tarfile.read().decode().startswith("2")

            if tarentry_filename.endswith(".crx"):
                with ZipFile(tarfile) as zf:
                    for zipentry in zf.infolist():
                        if is_source_file(zipentry):
                            with zf.open(zipentry) as f:
                                for block in mince_js(io.TextIOWrapper(f, encoding="utf-8", errors="surrogateescape")):
                                    file_lines = []
                                    file_lines += block.content.splitlines()
                                    file_lines += "".join(map(lambda x: x[1], block.string_literals)).splitlines()

                                    for search_tag in miner_strings.strings.keys():
                                        for search_string in miner_strings.strings[search_tag]:
                                            for line in file_lines:
                                                if search_string in line:
                                                    matches += [[zipentry.filename, search_tag, search_string]]
                                                    break

                                    for search_tag in miner_strings.patterns.keys():
                                        for search_pattern in miner_strings.patterns[search_tag]:
                                            for line in file_lines:
                                                m = re.search(search_pattern, line)
                                                if m:
                                                    matches += [[zipentry.filename, search_tag, m.group()]]
                                                    break
        for match in matches:
            results += [[date, crx_etag, name, version] + match]

    for result in results:
        print("|".join([str(x) for x in ([extid, still_in_store, crx_etags[-1]] + result)]))


def main(conf):
    logger = logging.getLogger()
    ch = logging.StreamHandler(sys.stderr)
    ch.setFormatter(logging.Formatter(const_log_format()))
    logger.addHandler(ch)
    if conf.verbose:
        logger.setLevel(logging.DEBUG)
    else:
        logger.setLevel(logging.WARNING)

    with open(conf.EXTID_FILE) as f:
        print("|".join(["extid", "still_in_store", "most_recent_crx_etag", "date", "crx_etag", "name", "version", "path", "tag", "match"]))
        for extid in [l.strip() for l in f.readlines()]:
            handle_extid(conf, extid)



if __name__ == "__main__":
    main_parser = argparse.ArgumentParser(
        formatter_class=argparse.RawTextHelpFormatter,
        description='Grep for extensions.')
    main_parser.add_argument(
        'REGEXP_FILE',
        help='python file with regular expressions')
    main_parser.add_argument(
        'EXTID_FILE',
        help='file with extension ids')
    main_parser.add_argument(
        '-v',
        '--verbose',
        action='store_true',
        default=False,
        help='increase verbosity')


    main_parser.add_argument(
        '-D',
        '--latest-date',
        metavar='DATE',
        type=str,
        help='select latest crx from tar, released before DATE.\n' +
        'Together with --from-date, specifies all crx released in specified\n'
        + 'date range.')

    main_parser.add_argument(
        '-d',
        '--from-date',
        metavar='DATE',
        type=str,
        help='select oldest crx from tar released after DATE.\n' +
        'Together with --latest-date, specifies all crx released in specified\n'
        + 'date range.')

    main_parser.add_argument(
        '-a',
        '--archive-dir',
        metavar='archive',
        type=str,
        default=const_basedir(),
        help='archive directory')

    # comment_group = main_parser.add_argument_group('comment blocks')
    # comment_group.add_argument(
    #     '-g',
    #     '--group-single-line-comments',
    #     help='Group consecutive singe-line comments into blocks')
    # comment_group.add_argument(
    #     '-c',
    #     '--reg-exp-comments',
    #     metavar='REGEXP',
    #     type=str,
    #     nargs='+',
    #     help='search comments for regular expression')

    # source_group = main_parser.add_argument_group('source blocks')
    # source_group.add_argument(
    #     '-b',
    #     '--beautify',
    #     action='store_true',
    #     default=False,
    #     help='beautify source code')
    # source_group.add_argument(
    #     '-s',
    #     '--reg-exp-source',
    #     metavar='REGEXP',
    #     type=str,
    #     nargs='+',
    #     help='search source for regular expression')

    # strings_group = main_parser.add_argument_group('string literals')
    # strings_group.add_argument(
    #     '-j',
    #     '--join-string-literals',
    #     action='store_true',
    #     help='join string literals (heuristic)')
    # strings_group.add_argument(
    #     '-l',
    #     '--reg-exp-string-literals',
    #     metavar='REGEXP',
    #     type=str,
    #     nargs='+',
    #     help='search string literals for regular expression')
    main_conf = main_parser.parse_args()

    sys.exit(main(main_conf))
